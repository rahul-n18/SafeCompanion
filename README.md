<div align="center">

# ğŸ›¡ï¸ SafeCompanion

### *Your AI Guardian - Real-time Vision & Voice Protection*

<img src="https://raw.githubusercontent.com/yourusername/safecompanion/main/demo.gif" alt="SafeCompanion Demo" width="700"/>

[![Live Demo](https://img.shields.io/badge/ğŸš€_Live_Demo-Try_Now-brightgreen?style=for-the-badge)](https://safecompanion.demo)
[![React](https://img.shields.io/badge/React-18+-61DAFB?style=for-the-badge&logo=react&logoColor=black)](https://reactjs.org/)
[![Gemini](https://img.shields.io/badge/Gemini-2.5_Flash-8E75B2?style=for-the-badge&logo=google)](https://ai.google.dev/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)](LICENSE)

[Features](#features) â€¢ [Demo](#demo) â€¢ [Installation](#installation) â€¢ [Usage](#usage) â€¢ [Tech Stack](#tech-stack)

</div>

---

## ğŸ¯ What is SafeCompanion?

SafeCompanion is a **multimodal AI agent** built with React and Google's Gemini Live API that acts as a proactive guardian for **elderly individuals** and the **visually impaired**. It simultaneously processes real-time video (camera) and audio (microphone) to provide safety monitoring, navigation assistance, and companionship.


<img width="340" height="559" alt="Screenshot 2025-11-29 at 5 19 56â€¯PM" src="https://github.com/user-attachments/assets/54834153-e0ba-4483-9bb7-a48d54b70fa8" />




**Unlike traditional chatbots**, SafeCompanion uses WebSocket streaming for continuous perceptionâ€”it doesn't just respond, it actively watches and protects.

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ‘´ **Companion Mode** (Elderly Care)
- ğŸš¨ **Fall Detection** with instant emergency alerts
- ğŸ’Š **Medication Tracking** with drug interaction warnings
- ğŸ’™ **Loneliness Detection** through voice analysis
- ğŸ§  **Long-term Memory** of family & preferences

</td>
<td width="50%">

### ğŸ‘ï¸ **Visual Guide Mode** (Blind/Low Vision)
- ğŸš§ **Obstacle Detection** in real-time
- ğŸ§ **Spatial Audio** navigation (3D sound cues)
- ğŸ‘‹ **Gesture Control** (thumbs up, open palm)
- ğŸ“– **Scene Description** & text reading

</td>
</tr>
</table>

---

## ğŸ¬ Demo

<div align="center">
<img width="340" height="559" alt="Screenshot 2025-11-29 at 5 20 20â€¯PM" src="https://github.com/user-attachments/assets/5491d090-b3f8-4ce9-9910-9c4528095726" />
<img width="340" height="559" alt="Screenshot 2025-11-29 at 5 20 35â€¯PM" src="https://github.com/user-attachments/assets/f608e5d6-ac06-495d-98a7-bcefa946bc10" />
<img width="340" height="559" alt="Screenshot 2025-11-29 at 5 20 43â€¯PM" src="https://github.com/user-attachments/assets/63b4e904-cfe3-4684-aa82-2d052c4906af" />



</div>

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 16+
- Gemini API key ([Get one free](https://ai.google.dev/))
- Camera + Microphone

Clone the repo
git clone https://github.com/yourusername/safecompanion.git
cd safecompanion

Install dependencies
npm install

Set up environment
cp .env.example .env

Add your VITE_GEMINI_API_KEY to .env
Start development server
npm run dev




### Installation


Visit `http://localhost:5173` and grant camera/microphone permissions.

---

## ğŸ’¡ Usage Example

**Medication Safety Check:**
User: "Can I take this?" [Shows pill bottle to camera]

AI: "That's Aspirin 81mg. I see you're taking Warfarinâ€”
this combination increases bleeding risk.
I'm flagging this for your doctor's review."

text

**Navigation Assistance:**
AI: "Chair detected 2 feet ahead on your right."
[Audio pans to right ear]

User: [Thumbs up gesture]

AI: "Step 3 feet left to bypass. Door ahead in 5 feet."

text

---

## ğŸ—ï¸ Architecture

<div align="center">

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Camera â”‚â”€â”€â”
â”‚ Microphone â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WebSocket â”‚
â”‚ Stream â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Gemini 2.5 Flash â”‚
â”‚ (Live API) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio â”‚ â”‚ Tool â”‚
â”‚ Responseâ”‚ â”‚ Calls â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

text

</div>

**Key Components:**
- **Audio Pipeline**: 16kHz PCM encoding/decoding with Web Audio API
- **Video Processing**: 4 FPS JPEG compression via Canvas API
- **Function Calling**: 15+ tools (fall detection, memory, device control)
- **Spatial Audio**: StereoPannerNode for 3D navigation cues

---

## ğŸ› ï¸ Tech Stack

<div align="center">

![React](https://img.shields.io/badge/React-18.2-61DAFB?style=flat-square&logo=react&logoColor=black)
![TypeScript](https://img.shields.io/badge/TypeScript-5.0-3178C6?style=flat-square&logo=typescript&logoColor=white)
![Vite](https://img.shields.io/badge/Vite-4.3-646CFF?style=flat-square&logo=vite&logoColor=white)
![Gemini](https://img.shields.io/badge/Gemini-2.5_Flash-8E75B2?style=flat-square&logo=google)

</div>

- **Frontend**: React + TypeScript + TailwindCSS
- **AI Model**: Google Gemini 2.5 Flash (multimodal streaming)
- **Audio**: Web Audio API, custom PCM pipeline
- **Video**: Canvas API for frame capture
- **State**: React hooks + localStorage RAG

---

## ğŸ“‚ Project Structure

safecompanion/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”œâ”€â”€ LiveAssistant.tsx # Core WebSocket logic
â”‚ â”‚ â”œâ”€â”€ CompanionMode.tsx # Elderly UI
â”‚ â”‚ â””â”€â”€ VisualGuideMode.tsx # Navigation UI
â”‚ â”œâ”€â”€ services/
â”‚ â”‚ â”œâ”€â”€ audioUtils.ts # PCM encoding/decoding
â”‚ â”‚ â”œâ”€â”€ memoryService.ts # RAG-based storage
â”‚ â”‚ â””â”€â”€ apiService.ts # Gemini API
â”‚ â”œâ”€â”€ constants.ts # System prompts & tools
â”‚ â””â”€â”€ App.tsx # Mode router
â”œâ”€â”€ .env.example
â””â”€â”€ package.json

text

---

## ğŸ¤ Contributing

Contributions welcome! Please follow these steps:

1. Fork the repo
2. Create a branch: `git checkout -b feature/AmazingFeature`
3. Commit changes: `git commit -m 'âœ¨ Add AmazingFeature'`
4. Push: `git push origin feature/AmazingFeature`
5. Open a Pull Request

---

## ğŸ” Privacy

- âœ… All data processed **locally** (no external database)
- âœ… Audio/video streams **not recorded**
- âœ… API keys stay on **your device**
- âœ… User controls all emergency alerts

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

Built with [Google Gemini Live API](https://ai.google.dev/gemini-api/docs/live-guide) | Inspired by healthcare & accessibility communities

---

<div align="center">

**â­ Star this repo if you found it helpful!**

Made with â¤ï¸ for those who need AI that truly cares.

</div>

